# Problem Statement:
The score of a sequence $[s_1, s_2, \ldots, s_d]$ is defined as $\displaystyle \frac{s_1\cdot s_2\cdot \ldots \cdot s_d}{d!}$, where $d!=1\cdot 2\cdot \ldots \cdot d$. In particular, the score of an empty sequence is $1$.

For a sequence $[s_1, s_2, \ldots, s_d]$, let $m$ be the maximum score among all its subsequences. Its cost is defined as the maximum length of a subsequence with a score of $m$.

You are given a **non-decreasing** sequence $[a_1, a_2, \ldots, a_n]$ of integers of length $n$. In other words, the condition $a_1 \leq a_2 \leq \ldots \leq a_n$ is satisfied. For each $k=1, 2, \ldots , n$, find the cost of the sequence $[a_1, a_2, \ldots , a_k]$.

A sequence $x$ is a subsequence of a sequence $y$ if $x$ can be obtained from $y$ by deletion of several (possibly, zero or all) elements.

The main function of the solution is defined as: 
```cpp
class Solution {
public:
    vector<int> solve(int &n, vector<int> &a) {   
        // write your code here
    }
};
```
Where:  
- `n` is an integer representing the size of the array.  
- `a` is a vector of integers, representing the given non-decreasing array.  
- The function should return a vector of integers, where the k-th element represents the cost of the subsequence $[a_1, a_2, \ldots, a_k]$.

# Example 1:
- Input:  
n = 3  
a = [1, 2, 3]
- Output:  
[1, 1, 2]

# Constraints:
- $1 \leq n \leq 100000$  
- $1 \leq a_i \leq n$  
- Time limit: 1000 ms  
- Memory limit: 1280 KB